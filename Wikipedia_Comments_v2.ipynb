{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rllxOvufW14"
      },
      "source": [
        "# Collect User Statistics on *Talk* Pages\n",
        "\n",
        "## Background\n",
        "\n",
        "Talk (German: Diskussion) pages are used to suggest changes to the associated main article. They are actively used primarily by readers who want to add or correct content, but are either reluctant to make the changes directly or are unsure how generalizable their request is. Political pages tend to have more talk threads than purely scientific, informative pages. A talk page is divided into sections, each of which forms a discussion thread - there is no official format for discussion threads. Users with administrative rights decide when to archive a page and create a new discussion page. When a user wants to start a new discussion, they edit the discussion page and add a new section with a title and explanation. Random readers, but especially users who are subscribed to the page in question, respond to the new topic. Subscribed users largely form the pool of main editors of the article in question. Thus, they set the direction, tone, and style of an article. Many do clean-up work that gives them enough standing to gain more rights, such as the role of administrator.\n",
        "\n",
        "Given the political dimension of the worldwide use of glyphosate-containing herbicides, currently controlled by Bayer CropScience, the number of existing talk pages is astonishing when comparing the German and English versions of Glyphosate.\n",
        "\n",
        "Wikimedia provides an API that allows aggregate statistics to be collected on users unless they have explicitly opted out. However, these tools do not cover talk pages. The purpose of this notebook is to explore that part.\n",
        "\n",
        "\n",
        "## Content\n",
        "\n",
        "Here we are looking into a specific page, namely Glyphosate on the German wikipedia and collect the following statistics as listed below.\n",
        "\n",
        "- **Total number of comments**. Comments given by users in total irrespective of the number of threads. Users can be counted multiple times.\n",
        "- **First Commentator Rate**. Count how often a user starts a thread, i.e., they are the first commentator. The count is divided by the total number of threads that are considered.\n",
        "- **Second Commentator Rate**. Count how often a user is the first one who reacts to a newly opened thread. The count is divided by the total number of threads that are considered.\n",
        "- **Reaction Rate**. Aggregate counts for users who react to a thread, i.e., they might be the second or fourth commentator. They are counted only once per thread. The count is divided by the total number of threads that are considered.\n",
        "\n",
        "\n",
        "## Usage\n",
        "\n",
        "This notebook is a [Jupyter](https://jupyter.org) notebook hosted by Google (see [Colab](https://research.google.com/colaboratory/faq.html)) and can be run instantly on your account. Alternatively, you can run this notebook on your personal Jupyter installation.\n",
        "There are two types of cells: text (like this) and code cells (subsequent cell). To retrieve the final figures you need to execute all code cells. \n",
        "To run a cell you mark a cell and click the run icon occurring on the top left corner (or press CMD + Return). To run the analysis on a different wikipedia page, replace the PAGE_URL in the code cell below.\n",
        "\n",
        "You can try other topics by replacing the url stored in the PAGE_URL variable (line 4 below). As this parser could not be tested against all existing topics, you may encounter script errors if the html format differs. In such a case, do not hesitate to report errors on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### any changes in this cell require a re-run of the subsequent cell\n",
        "## paste here any url of the page you are interest in\n",
        "#PAGE_URL = 'https://en.wikipedia.org/wiki/Glyphosate'\n",
        "PAGE_URL = 'https://de.wikipedia.org/wiki/Glyphosat'\n",
        "\n",
        "## display only the top k editors w.r.t. total number of edits in a figure\n",
        "TOPK = 25\n",
        "\n",
        "# look only at edits after indicated stard date (format dd-mm-yyyy)\n",
        "START_DATE_STR = '01-01-2015'"
      ],
      "metadata": {
        "id": "MQ8RtShigHXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pylab as plt\n",
        "from pandas import DataFrame\n",
        "from prompt_toolkit.completion.fuzzy_completer import namedtuple\n",
        "import re\n",
        "import requests\n",
        "import seaborn as snb\n",
        "import sys\n",
        "import time\n",
        "from typing import List, Union\n",
        "from urllib.request import urlopen"
      ],
      "metadata": {
        "id": "bf0EUJ-JnVMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Definitions\n",
        "START_DATE = time.strptime(START_DATE_STR, '%d-%m-%Y')\n",
        "\n",
        "print('INFO:\\tedits before {}-{}-{} will be ignored'.format(START_DATE.tm_mday, START_DATE.tm_mday, START_DATE.tm_year))\n",
        "\n",
        "PAGE_RX = re.compile(r'^https\\:\\/\\/(\\w{2})\\.wikipedia\\.org.+?\\/(.+)$')\n",
        "LANG = None\n",
        "TOPIC = None\n",
        "try:\n",
        "  LANG = PAGE_RX.match(PAGE_URL).groups()[0]\n",
        "  TOPIC = PAGE_RX.match(PAGE_URL).groups()[1]\n",
        "  print('INFO:\\tdetected country code is \"{}\"'.format(LANG))\n",
        "  print('INFO:\\ttopic of the page is \"{}\"'.format(TOPIC))\n",
        "except:\n",
        "  print('Error: could not extract country code or page title (topic). Check the url!')\n",
        "\n",
        "## url extensions for some languages; list missing ones if needed\n",
        "TALK_URL_EXT = {'en': 'Talk', 'de': 'Diskussion', 'fr': 'Discussion', 'es': 'DiscusiÃ³n', 'it': 'Discussione'}\n",
        "TALK_RXV_URL_EXT = {'de': 'Archiv', 'en': 'Archive'}\n",
        "RXV_RULES = ['https://{}.wikipedia.org/wiki/{}:{}/{}/{}', 'https://{}.wikipedia.org/wiki/{}:{}/{}_{}']\n"
      ],
      "metadata": {
        "id": "Fm1LEXuvhNnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p19sDBPQUrTx"
      },
      "outputs": [],
      "source": [
        "def init_session():\n",
        "  \"\"\" (Re)Start session and re-use for session obj multiple queries. \"\"\"\n",
        "  return requests.Session()\n",
        "\n",
        "def get_api_url(params: dict=None):\n",
        "  api_url = 'https://{}.wikipedia.org/w/api.php'.format(LANG)\n",
        "  if params:\n",
        "    api_url += '?' + '&'.join([k + '=' + str(v) for k, v in params.items()])\n",
        "  return api_url\n",
        "\n",
        "def get_link(pageid:Union[int, str]):\n",
        "  return 'https://{}.wikipedia.org/w/index.php?curid={}'.format(LANG, pageid)\n",
        "\n",
        "class UserStats():\n",
        "\n",
        "  def __init__(self, lang: str, title: str):\n",
        "    self.lang = lang\n",
        "    self.title = title\n",
        "    self.threads = {}  # thread_id: [usr1, usr2, ...]\n",
        "  \n",
        "  def add_threads(self, threads: dict):\n",
        "    self.threads.update(threads)\n",
        "\n",
        "  def get_thread_start_count(self) -> List:\n",
        "    \"\"\" Return Top k users starting a thread and their counts. \"\"\"\n",
        "    return Counter([l[0] for l in self.threads.values() if len(l)]).most_common(TOPK)\n",
        "\n",
        "  def get_first_comment_count(self) -> List:\n",
        "    \"\"\" Return Top k users commenting first a thread, \n",
        "        but are not the thread initiator.\n",
        "\n",
        "        Normalized by total number of threads for same topic.\n",
        "    \"\"\"\n",
        "    second = [l[1] for l in self.threads.values() if len(l) > 1]\n",
        "    return Counter(second).most_common(TOPK)\n",
        "\n",
        "  def get_reaction_count(self) -> List:\n",
        "    \"\"\" Return Top k users commenting on existing thread.\n",
        "    \n",
        "        Includes first commentators, but not thread creators.\n",
        "        Normalized by number of threads.\n",
        "    \"\"\"\n",
        "    secondplus = [v for l in self.threads.values() for v in l[1:] if len(l) > 1]\n",
        "    return Counter(secondplus).most_common(TOPK)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RX_USER = re.compile(r'^h-([a-zA-Z_\\d]+)?-.+')\n",
        "TS_USR = re.compile('__DTLATESTCOMMENTTHREAD__\\{\"id\"\\:\"c\\-(.+)?-\\d{14}')\n",
        "T_USR = re.compile('span data\\-mw\\-comment\\-start\\=\"\" id=\"c\\-([_a-z\\u00fcA-Z-]+)?\\-\\d{4}\\-\\d{2}-\\d{2}')\n",
        "THREAD_START = '<div class=\"mw-heading'\n",
        "THREAD_ID = re.compile('span\\sclass')\n",
        "TS = 'span class=\"mw-headline\" id=\"'\n",
        "TE = '\" data-mw-thread-id='\n",
        "CS = re.compile('span data\\-mw\\-comment\\-start\\=\"\" id=\"c\\-([^-]+)?\\-((\\d{4}\\-\\d{2}-\\d{2}|\\d{14}))')\n",
        "TZ = re.compile('__DTLATESTCOMMENTTHREAD__{\"id\"\\:\"c\\-(.+)?\\d{4}-\\d{2}-\\d{2}T-\\d{2}:\\d{2}:\\d{2}\\.000Z')\n",
        "\n",
        "def url_exists(url: str) -> bool:\n",
        "  r = requests.head(url)\n",
        "  if r.status_code == 200:\n",
        "    print(f'{url} was found')\n",
        "    return True\n",
        "  else:\n",
        "    print(f'{url} was NOT found')\n",
        "  return False\n",
        "\n",
        "def generate_talk_url(idx: int, ctr: int):\n",
        "  if idx == 0:\n",
        "    return RXV_RULES[0].\\\n",
        "      format(LANG, TALK_URL_EXT[LANG], TOPIC, TALK_RXV_URL_EXT[LANG], \n",
        "           '0'*(3 - len(str(ctr))) + str(ctr))\n",
        "  elif idx == 1:\n",
        "    return RXV_RULES[1].\\\n",
        "      format(LANG, TALK_URL_EXT[LANG], TOPIC, TALK_RXV_URL_EXT[LANG], str(ctr))\n",
        "\n",
        "def get_all_talk_pages(page_url) -> List[str]:\n",
        "  \"\"\" Collect all talk pages (incl. archived) with threads started after START_DATE \"\"\"\n",
        "  talk_urls = []\n",
        "  if LANG not in TALK_URL_EXT:\n",
        "    raise Exception('URL suffix for \"{}\" talk page unknown. Give a hint!'.format(LANG))\n",
        "  talk_url = 'https://{}.wikipedia.org/wiki/{}:{}'.format(LANG, TALK_URL_EXT[LANG], TOPIC)\n",
        "  if url_exists(talk_url):\n",
        "    talk_urls.append(talk_url)\n",
        "  # try archive\n",
        "  talk_url = 'https://{}.wikipedia.org/wiki/{}:{}/{}'.\\\n",
        "    format(LANG, TALK_URL_EXT[LANG], TOPIC, TALK_RXV_URL_EXT[LANG])\n",
        "  if url_exists(talk_url):\n",
        "    talk_urls.append(talk_url)\n",
        "  # try older archived once\n",
        "  ctr = 1\n",
        "  rule_idx = None\n",
        "\n",
        "  for i in range(len(RXV_RULES)):\n",
        "    talk_url = generate_talk_url(i, ctr)\n",
        "    if url_exists(talk_url):\n",
        "      rule_idx = i\n",
        "      break\n",
        "\n",
        "  while rule_idx is not None and url_exists(talk_url) and ctr < 99:\n",
        "    talk_urls.append(talk_url)\n",
        "    ctr += 1\n",
        "    talk_url = generate_talk_url(rule_idx, ctr)\n",
        "\n",
        "  if not len(talk_urls):\n",
        "    print('No talk page archives found')\n",
        "  return talk_urls\n",
        "\n",
        "def parse_talk_page(url: str) -> dict:\n",
        "  \"\"\" Collect user statistics for talk page given by url. \"\"\"\n",
        "  page = urlopen(url)\n",
        "  html_bytes = page.read()\n",
        "  html = html_bytes.decode(\"utf-8\")\n",
        "  pos_ts = html.find(TS, 0)\n",
        "  threads = {}\n",
        "  n = len(html)\n",
        "  pos_te = html.find(TE, pos_ts+1)\n",
        "  if pos_te == -1:\n",
        "    return {}\n",
        "  thread_id = html[pos_ts+len(TS):pos_te]\n",
        "  threads[thread_id] = []\n",
        "  pos_ts_next = html.find(TS, pos_te)\n",
        "  if pos_ts_next == -1:\n",
        "    pos_ts_next = n\n",
        "  for m in re.finditer(CS, html):\n",
        "    usr, ts_str = m[1], m[2]\n",
        "    try:\n",
        "      ts = time.strptime(ts_str, '%Y-%m-%d')\n",
        "    except:\n",
        "      try:\n",
        "        if ts_str.startswith('20'):\n",
        "          ts = time.strptime(ts_str[:8], '%Y%m%d')\n",
        "      except:\n",
        "        print('WARNING: date could not be extracted from ', ts_str, '. Filtering by date will be ignored.')\n",
        "      year = None\n",
        "    if ts < START_DATE:\n",
        "      continue\n",
        "    if m.start(1) > pos_ts_next: # new thread started\n",
        "      pos_ts = pos_ts_next\n",
        "      eol = html.find('\\n', pos_ts)\n",
        "      pos_te = html.find(TE, pos_ts+1)\n",
        "      assert pos_te > -1\n",
        "      pos_ts_next = html.find(TS, pos_te)\n",
        "      if pos_ts_next == -1:\n",
        "        pos_ts_next = n\n",
        "      thread_id = html[pos_ts+len(TS):pos_te]\n",
        "      threads[thread_id] = []\n",
        "    threads[thread_id].append(usr)\n",
        "  return threads"
      ],
      "metadata": {
        "id": "SwYZYraAMmvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_talk_pages() -> UserStats:\n",
        "  \"\"\" Collect user statistics for talk page given by url. \"\"\"\n",
        "  user_stats = dict()\n",
        "  us = UserStats(LANG, TOPIC)\n",
        "  for page in get_all_talk_pages(PAGE_URL):\n",
        "    threads = parse_talk_page(page) \n",
        "    us.add_threads(threads)\n",
        "  return us\n",
        "us = parse_talk_pages()"
      ],
      "metadata": {
        "id": "SEcsbd-wwQPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(us.get_thread_start_count())\n",
        "print(us.get_first_comment_count())\n",
        "print(us.get_reaction_count())"
      ],
      "metadata": {
        "id": "D50DAQ1_pk4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results\n",
        "### Show Users Starting a Thread"
      ],
      "metadata": {
        "id": "kf-Wirupwunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = DataFrame(us.get_thread_start_count(), columns=['user', 'count'])\n",
        "snb.barplot(x=df['user'], y=df['count']).set_title('Top {} Thread Starters in {} Discussions'.format(TOPK, TOPIC))\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kixv7Y8u5NaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Users Reacting First to a Newly Started Thread"
      ],
      "metadata": {
        "id": "qru88p9Bxp6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = DataFrame(us.get_first_comment_count(), columns=['user', 'count'])\n",
        "snb.barplot(x=df['user'], y=df['count']).set_title('Top {} Users Reacting First to New Thread {} Discussions'.format(TOPK, TOPIC))\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NTmA-zXI9y1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Users Reacting to, but not Starting a Thread\n",
        "includes users reacting first, second, third, etc.\n"
      ],
      "metadata": {
        "id": "um7gwlmgx7Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = DataFrame(us.get_reaction_count(), columns=['user', 'count'])\n",
        "snb.barplot(x=df['user'], y=df['count']).set_title('Top {} Users Reacting to a Thread in {} Discussions'.format(TOPK, TOPIC))\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KXZ59iJ1uvJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}